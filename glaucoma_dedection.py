# -*- coding: utf-8 -*-
"""glaucomaDedection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mL2Tkk8fPyodcPdZVoJP_6SzrjVHmSLl

# Import necessary libraries
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import PIL.Image
import tensorflow_datasets as tfds
import pathlib

# Set the default figure size for matplotlib
plt.rcParams['figure.figsize'] = (7,7) # Make the figures a bit bigger

"""# Load data and preprocess it

## Option 1:
Download the dataset directly from the provided link. If this does not work, try Option **2**
"""

dataset_url = 'http://vision.roboslang.org/open_datasets/Fundus_images.zip'

"""## Option 2:
If downloading the dataset from the link is too slow or the link is no longer working, download the dataset from Brigthspace, and upload it to the sample_data folder in Google Colab. Uncomment the second line in the command below to point to the dataset url

"""

# For option 2, after you have copied the data locally, point the dataset_url to the local path
# Remember to uncomment the line below
# dataset_url = '/content/sample_data/datasets/glaucoma_dataset.zip'
# dataset_url = '/content/datasets/Fundus_images.zip'

out_path = '/content/sample_data/'
archive = tf.keras.utils.get_file(origin=dataset_url, cache_dir='/content/sample_data/', extract=True)

# Create a 'pathlib.Path' object for the downloaded archive
# Pathlib module offers classes representing filesystem paths with semantics
# appropriate for different operating systems.
data_dir = pathlib.Path(archive).with_suffix('')

# Count the number of images in a specific directory
print("Train:",len(list(data_dir.glob('./Train/Glaucoma_Positive/*.jpg'))) ,"|||", "Test:",len(list(data_dir.glob('./Test/Glaucoma_Positive/*.jpg'))))

# BEGIN YOUR CODE HERE

# Glaucoma dataset is split into train and test folders. Inside those folders you will
# find additional folders: Glaucoma_Negative and Glaucoma_Positve. You can explore the folders using
# 'Files' tab from the right hand side.
# Tip: use the len() function


positiveTrain = len(list(data_dir.glob('./Train/Glaucoma_Positive/*.jpg')))
negativeTrain = len(list(data_dir.glob('./Train/Glaucoma_Negative/*.jpg')))

postiveTest = len(list(data_dir.glob('./Test/Glaucoma_Positive/*.jpg')))
negativeTest= len(list(data_dir.glob('./Test/Glaucoma_Negative/*.jpg')))

print("Train positive:",positiveTrain ,"|||||||||", "Train negative:",negativeTrain)
print("Test positive:",postiveTest ,"|||||||||", "Test negative:",negativeTest)

# END YOUR CODE HERE

# Create a list of file paths for glaucoma images
positive_images = list(data_dir.glob('Train/Glaucoma_Positive/*'))
# Open and display the first glaucoma image in the list
PIL.Image.open(str(positive_images[0]))

positive = PIL.Image.open(str(list(data_dir.glob('Test/Glaucoma_Positive/*.jpg'))[0]))
negative = PIL.Image.open(str(list(data_dir.glob('Test/Glaucoma_Negative/*.jpg'))[0]))

plt.figure(figsize=(15, 10))

plt.subplot(1, 2, 1)
plt.imshow(positive)

plt.subplot(1, 2, 2)
plt.imshow(negative)

plt.show()

"""# Define a deep learning model that will learn the differences between glaucoma and normal fundus images

"""

# Define batch size and image dimensions for training

# BEGIN YOUR CODE HERE
# The batch size is the number of samples processed before the model is updated.
# Choose an appropriate batch size. What are the images resolutions?

batch_size = 32

img_height = 256
img_width = 256

# END YOUR CODE HERE

train_data_dir  = os.path.join(data_dir,'Train')
test_data_dir = os.path.join(data_dir,'Test')

# Create a TensorFlow image dataset from a directory
# BEGIN YOUR CODE HERE
# Use the function tf.keras.utils.image_dataset_from_directory in order to load
# the training dataset: https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory
# 1. First argument is your training directory folder,
# 2. Use 20% of the data for validation, for image size,
# 3. name the subset as "training"
# 4. you can set a seed such that when you repeat experiments you get similar results, eg: seed=123
# 5. for image size use the img_height and img_width variables you defined previously.
# 6. Use for batch size the batch_size variable you defined earlier in the code
# tf.keras.utils.image_dataset_from_directory(
#     directory,
#     validation_split=None,
#     subset='',
#     seed=None,
#     image_size=(height, width),
#     batch_size=-1
# )
# eg: train_ds = tf.keras.utils.image_dataset_from_directory(...)


# Create validation dataset and call that val_ds, by getting the 'validation' subset


seedVar = 123

train_ds = tf.keras.utils.image_dataset_from_directory(
    train_data_dir,
    validation_split=0.2,
    subset='training',
    seed=seedVar,
    image_size=(img_height, img_width),
    batch_size=batch_size
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    train_data_dir,
    validation_split=0.2,
    subset='validation',
    seed=seedVar,
    image_size=(img_height, img_width),
    batch_size=batch_size
)



normalization_layer = tf.keras.layers.Rescaling(1./255)

normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
image_batch, labels_batch = next(iter(normalized_ds))
first_image = image_batch[0]

print(np.min(first_image), np.max(first_image), first_image[0][0])

num_classes = 2


modelOne = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(6, (5, 5), activation='relu', input_shape=(img_height, img_width, 3)),
    tf.keras.layers.AveragePooling2D((2, 2)),
    tf.keras.layers.Conv2D(16, (5, 5), activation='relu'),
    tf.keras.layers.AveragePooling2D((2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(120, activation='relu'),
    tf.keras.layers.Dense(84, activation='relu'),
    tf.keras.layers.Dense(num_classes, activation='softmax')
])

modelTwo = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(96, (11, 11), strides=4, activation='relu', input_shape=(img_height, img_width, 3)),
    tf.keras.layers.MaxPooling2D((3, 3), strides=2),
    tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D((3, 3), strides=2),
    tf.keras.layers.Conv2D(384, (3, 3), padding='same', activation='relu'),
    tf.keras.layers.Conv2D(384, (3, 3), padding='same', activation='relu'),
    tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D((3, 3), strides=2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(4096, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(4096, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(num_classes, activation='softmax')
])

baseModel = tf.keras.applications.EfficientNetB0(
    include_top=False,
    weights='imagenet',
    input_shape=(img_height, img_width, 3)
)

modelThree = tf.keras.models.Sequential([
  baseModel,
  tf.keras.layers.GlobalAveragePooling2D(),
  tf.keras.layers.Dropout(0.5),
  tf.keras.layers.Dense(num_classes, activation='softmax')
])

modelOne.compile(
  optimizer='adam',
  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
  metrics=['accuracy'])

modelTwo.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)

modelThree.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)

trainModelOne = modelOne.fit(train_ds, epochs=5, verbose=1, validation_data=val_ds)

trainModelTwo = modelTwo.fit(train_ds, epochs=5, verbose=1, validation_data=val_ds)

trainModelThree = modelThree.fit(train_ds, epochs=5, verbose=1, validation_data=val_ds)

train_loss1 = trainModelOne.history['loss']
val_loss1 = trainModelOne.history['val_loss']

train_loss2 = trainModelTwo.history['loss']
val_loss2 = trainModelTwo.history['val_loss']

train_loss3 = trainModelThree.history['loss']
val_loss3 = trainModelThree.history['val_loss']

epochs = range(1, len(train_loss1) + 1)

plt.figure(figsize=(10, 8))

plt.plot(epochs, train_loss1, label='1 - Training Loss', color='red', linestyle='-', marker='o')
plt.plot(epochs, val_loss1, label=' 1 - Validation Loss', color='red', linestyle='--', marker='x')

plt.plot(epochs, train_loss2, label='2 - Training Loss', color='green', linestyle='-', marker='o')
plt.plot(epochs, val_loss2, label='2 - Validation Loss', color='green', linestyle='--', marker='x')

plt.plot(epochs, train_loss3, label='3 - Training Loss', color='blue', linestyle='-', marker='o')
plt.plot(epochs, val_loss3, label='3 - Validation Loss', color='blue', linestyle='--', marker='x')

plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss Over Epochs for All Models')
plt.grid(True)
plt.legend()

plt.show()

test_ds = tf.keras.utils.image_dataset_from_directory(
  test_data_dir,
  image_size=(img_height, img_width),
  batch_size=batch_size)

test_loss1, test_accuracy1 = modelOne.evaluate(test_ds, verbose=1)
test_loss2, test_accuracy2 = modelTwo.evaluate(test_ds, verbose=1)
test_loss3, test_accuracy3 = modelThree.evaluate(test_ds, verbose=1)

